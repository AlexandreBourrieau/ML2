{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 72.044256,
      "end_time": "2021-07-30T20:14:17.335759",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-07-30T20:13:05.291503",
      "version": "2.3.3"
    },
    "colab": {
      "name": "DSTPI_SP500_RAYTUNE.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:13:13.998275Z",
          "iopub.status.busy": "2021-07-30T20:13:13.996458Z",
          "iopub.status.idle": "2021-07-30T20:13:21.014938Z",
          "shell.execute_reply": "2021-07-30T20:13:21.014317Z",
          "shell.execute_reply.started": "2021-07-30T11:41:48.232313Z"
        },
        "id": "9cb58cf9",
        "papermill": {
          "duration": 7.090356,
          "end_time": "2021-07-30T20:13:21.015150",
          "exception": false,
          "start_time": "2021-07-30T20:13:13.924794",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from keras import backend as K"
      ],
      "id": "9cb58cf9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:13:21.149274Z",
          "iopub.status.busy": "2021-07-30T20:13:21.148612Z",
          "iopub.status.idle": "2021-07-30T20:13:37.904234Z",
          "shell.execute_reply": "2021-07-30T20:13:37.903523Z",
          "shell.execute_reply.started": "2021-07-30T11:41:55.409626Z"
        },
        "id": "0d50f90d",
        "papermill": {
          "duration": 16.825266,
          "end_time": "2021-07-30T20:13:37.904392",
          "exception": false,
          "start_time": "2021-07-30T20:13:21.079126",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "!pip install -q 'ray[tune]' 'ray[default]'\n",
        "!pip install -q --upgrade aioredis==1.3.1"
      ],
      "id": "0d50f90d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62d839e0",
        "papermill": {
          "duration": 0.064155,
          "end_time": "2021-07-30T20:13:38.035826",
          "exception": false,
          "start_time": "2021-07-30T20:13:37.971671",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Initialisation TPU"
      ],
      "id": "62d839e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "707858cc",
        "papermill": {
          "duration": 0.063299,
          "end_time": "2021-07-30T20:13:38.162907",
          "exception": false,
          "start_time": "2021-07-30T20:13:38.099608",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Les TPU sont des calculateurs qui sont différents du processeur local exécutant le programme Python. Pour travailler avec les TPU, il faut donc commencer par se connecter au cluster distant et les initialiser."
      ],
      "id": "707858cc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:13:38.307809Z",
          "iopub.status.busy": "2021-07-30T20:13:38.306799Z",
          "iopub.status.idle": "2021-07-30T20:13:51.801232Z",
          "shell.execute_reply": "2021-07-30T20:13:51.801740Z",
          "shell.execute_reply.started": "2021-07-30T11:43:16.107351Z"
        },
        "id": "1c08f669",
        "papermill": {
          "duration": 13.573607,
          "end_time": "2021-07-30T20:13:51.801906",
          "exception": false,
          "start_time": "2021-07-30T20:13:38.228299",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "id": "1c08f669",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "173f3719",
        "papermill": {
          "duration": 0.064294,
          "end_time": "2021-07-30T20:13:51.930119",
          "exception": false,
          "start_time": "2021-07-30T20:13:51.865825",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Chargement et correction des données"
      ],
      "id": "173f3719"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "facc78ad",
        "papermill": {
          "duration": 0.065339,
          "end_time": "2021-07-30T20:13:52.060711",
          "exception": false,
          "start_time": "2021-07-30T20:13:51.995372",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Le dataset utilisé est SP500..."
      ],
      "id": "facc78ad"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f895cd5",
        "papermill": {
          "duration": 0.064302,
          "end_time": "2021-07-30T20:13:52.190175",
          "exception": false,
          "start_time": "2021-07-30T20:13:52.125873",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**1. Chargement des fichiers CSV**"
      ],
      "id": "1f895cd5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:13:52.323887Z",
          "iopub.status.busy": "2021-07-30T20:13:52.323223Z",
          "iopub.status.idle": "2021-07-30T20:13:56.941833Z",
          "shell.execute_reply": "2021-07-30T20:13:56.941089Z",
          "shell.execute_reply.started": "2021-07-30T11:43:53.385860Z"
        },
        "id": "38d049e5",
        "papermill": {
          "duration": 4.685735,
          "end_time": "2021-07-30T20:13:56.941986",
          "exception": false,
          "start_time": "2021-07-30T20:13:52.256251",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "!rm *.csv\n",
        "!curl --location --remote-header-name --remote-name \"https://github.com/AlexandreBourrieau/FICHIERS/raw/main/Series_Temporelles/Multi/Data/SPX2010_2021.csv\"\n",
        "!curl --location --remote-header-name --remote-name \"https://github.com/AlexandreBourrieau/FICHIERS/raw/main/Series_Temporelles/Multi/Data/VIX2010_2021.csv\"\n",
        "!curl --location --remote-header-name --remote-name \"https://github.com/AlexandreBourrieau/FICHIERS/raw/main/Series_Temporelles/Multi/Data/US10Y2010_2021.csv\"\n",
        "!curl --location --remote-header-name --remote-name \"https://github.com/AlexandreBourrieau/FICHIERS/raw/main/Series_Temporelles/Multi/Data/TYVIX2010_2021.csv\"\n"
      ],
      "id": "38d049e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "144c3d56",
        "papermill": {
          "duration": 0.071131,
          "end_time": "2021-07-30T20:13:57.084397",
          "exception": false,
          "start_time": "2021-07-30T20:13:57.013266",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**2. Analyse et correction des données S&P500**"
      ],
      "id": "144c3d56"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:13:57.231931Z",
          "iopub.status.busy": "2021-07-30T20:13:57.231275Z",
          "iopub.status.idle": "2021-07-30T20:13:57.505692Z",
          "shell.execute_reply": "2021-07-30T20:13:57.504942Z",
          "shell.execute_reply.started": "2021-07-30T11:44:02.423757Z"
        },
        "id": "d7c72a07",
        "papermill": {
          "duration": 0.352223,
          "end_time": "2021-07-30T20:13:57.505882",
          "exception": false,
          "start_time": "2021-07-30T20:13:57.153659",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Création de la série sous Pandas\n",
        "df_SP500 = pd.read_csv(\"SPX2010_2021.csv\",sep=\";\",names=[\"Date\",\"SP500_O\",\"SP500_H\",\"SP500_L\",\"SP500_C\"],decimal=\",\")\n",
        "df_SP500['Date'] = pd.to_datetime(df_SP500['Date'])\n",
        "df_SP500 = df_SP500.set_index(\"Date\")\n",
        "df_SP500 = df_SP500.asfreq(freq=\"1D\")\n",
        "df_SP500"
      ],
      "id": "d7c72a07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:13:57.658067Z",
          "iopub.status.busy": "2021-07-30T20:13:57.657338Z",
          "iopub.status.idle": "2021-07-30T20:13:58.048932Z",
          "shell.execute_reply": "2021-07-30T20:13:58.049437Z",
          "shell.execute_reply.started": "2021-07-30T11:44:05.420732Z"
        },
        "id": "ebbaefa4",
        "papermill": {
          "duration": 0.473351,
          "end_time": "2021-07-30T20:13:58.049613",
          "exception": false,
          "start_time": "2021-07-30T20:13:57.576262",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.linspace(0,len(df_SP500),len(df_SP500)+1),y=df_SP500['SP500_C'], line=dict(color='blue', width=1),name=\"Index\"))\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "id": "ebbaefa4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c4e150f",
        "papermill": {
          "duration": 0.070998,
          "end_time": "2021-07-30T20:13:58.193012",
          "exception": false,
          "start_time": "2021-07-30T20:13:58.122014",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**2. Analyse et correction des données VIX**"
      ],
      "id": "8c4e150f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:13:58.346369Z",
          "iopub.status.busy": "2021-07-30T20:13:58.345311Z",
          "iopub.status.idle": "2021-07-30T20:13:58.563654Z",
          "shell.execute_reply": "2021-07-30T20:13:58.564156Z",
          "shell.execute_reply.started": "2021-07-30T11:44:11.167856Z"
        },
        "id": "548e0efb",
        "papermill": {
          "duration": 0.298068,
          "end_time": "2021-07-30T20:13:58.564321",
          "exception": false,
          "start_time": "2021-07-30T20:13:58.266253",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Création de la série sous Pandas\n",
        "df_VIX = pd.read_csv(\"VIX2010_2021.csv\",sep=\";\",names=[\"Date\",\"VIX_O\",\"VIX_H\",\"VIX_L\",\"VIX_C\"],decimal=\",\")\n",
        "df_VIX['Date'] = pd.to_datetime(df_VIX['Date'])\n",
        "df_VIX = df_VIX.set_index(\"Date\")\n",
        "df_VIX = df_VIX.asfreq(freq=\"1D\")\n",
        "df_VIX"
      ],
      "id": "548e0efb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:13:58.734871Z",
          "iopub.status.busy": "2021-07-30T20:13:58.734163Z",
          "iopub.status.idle": "2021-07-30T20:13:58.742937Z",
          "shell.execute_reply": "2021-07-30T20:13:58.742400Z",
          "shell.execute_reply.started": "2021-07-30T11:44:13.597361Z"
        },
        "id": "ff8873b7",
        "papermill": {
          "duration": 0.105656,
          "end_time": "2021-07-30T20:13:58.743097",
          "exception": false,
          "start_time": "2021-07-30T20:13:58.637441",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.linspace(0,len(df_VIX),len(df_VIX)+1),y=df_VIX['VIX_C'], line=dict(color='blue', width=1),name=\"Index\"))\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "id": "ff8873b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c958eb30",
        "papermill": {
          "duration": 0.073283,
          "end_time": "2021-07-30T20:13:58.890492",
          "exception": false,
          "start_time": "2021-07-30T20:13:58.817209",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**3. Analyse et correction des données US10Y**"
      ],
      "id": "c958eb30"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:13:59.045936Z",
          "iopub.status.busy": "2021-07-30T20:13:59.044934Z",
          "iopub.status.idle": "2021-07-30T20:13:59.290170Z",
          "shell.execute_reply": "2021-07-30T20:13:59.290690Z",
          "shell.execute_reply.started": "2021-07-30T11:44:17.587517Z"
        },
        "id": "f70e30e7",
        "papermill": {
          "duration": 0.325735,
          "end_time": "2021-07-30T20:13:59.290859",
          "exception": false,
          "start_time": "2021-07-30T20:13:58.965124",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Création de la série sous Pandas\n",
        "df_US10Y= pd.read_csv(\"US10Y2010_2021.csv\",sep=\";\",names=[\"Date\",\"US10Y_O\",\"US10Y_H\",\"US10Y_L\",\"US10Y_C\"],decimal=\",\")\n",
        "df_US10Y['Date'] = pd.to_datetime(df_US10Y['Date'])\n",
        "df_US10Y = df_US10Y.set_index(\"Date\")\n",
        "df_US10Y = df_US10Y.asfreq(freq=\"1D\")\n",
        "df_US10Y"
      ],
      "id": "f70e30e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:13:59.464952Z",
          "iopub.status.busy": "2021-07-30T20:13:59.459757Z",
          "iopub.status.idle": "2021-07-30T20:13:59.471741Z",
          "shell.execute_reply": "2021-07-30T20:13:59.471095Z",
          "shell.execute_reply.started": "2021-07-30T11:44:19.926775Z"
        },
        "id": "2309a2ff",
        "papermill": {
          "duration": 0.10688,
          "end_time": "2021-07-30T20:13:59.471881",
          "exception": false,
          "start_time": "2021-07-30T20:13:59.365001",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.linspace(0,len(df_US10Y),len(df_US10Y)+1),y=df_US10Y['US10Y_C'], line=dict(color='blue', width=1),name=\"Index\"))\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "id": "2309a2ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19a5aea1",
        "papermill": {
          "duration": 0.076348,
          "end_time": "2021-07-30T20:13:59.624587",
          "exception": false,
          "start_time": "2021-07-30T20:13:59.548239",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**4. Analyse et correction des données TYVIX**"
      ],
      "id": "19a5aea1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:13:59.800017Z",
          "iopub.status.busy": "2021-07-30T20:13:59.798930Z",
          "iopub.status.idle": "2021-07-30T20:13:59.933405Z",
          "shell.execute_reply": "2021-07-30T20:13:59.932515Z",
          "shell.execute_reply.started": "2021-07-30T11:44:23.714892Z"
        },
        "id": "7b25dfa2",
        "papermill": {
          "duration": 0.233256,
          "end_time": "2021-07-30T20:13:59.933607",
          "exception": false,
          "start_time": "2021-07-30T20:13:59.700351",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Création de la série sous Pandas\n",
        "df_TYVIX= pd.read_csv(\"TYVIX2010_2021.csv\",sep=\";\",names=[\"Date\",\"TYVIX_C\"],decimal=\",\")\n",
        "df_TYVIX['Date'] = pd.to_datetime(df_TYVIX['Date'])\n",
        "df_TYVIX = df_TYVIX.set_index(\"Date\")\n",
        "df_TYVIX = df_TYVIX.asfreq(freq=\"1D\")\n",
        "df_TYVIX"
      ],
      "id": "7b25dfa2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:00.141483Z",
          "iopub.status.busy": "2021-07-30T20:14:00.140474Z",
          "iopub.status.idle": "2021-07-30T20:14:00.147325Z",
          "shell.execute_reply": "2021-07-30T20:14:00.147900Z",
          "shell.execute_reply.started": "2021-07-30T11:44:26.127034Z"
        },
        "id": "4167fcf7",
        "papermill": {
          "duration": 0.117294,
          "end_time": "2021-07-30T20:14:00.148090",
          "exception": false,
          "start_time": "2021-07-30T20:14:00.030796",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.linspace(0,len(df_TYVIX),len(df_TYVIX)+1),y=df_TYVIX['TYVIX_C'], line=dict(color='blue', width=1),name=\"Index\"))\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "id": "4167fcf7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "487dbe43",
        "papermill": {
          "duration": 0.079064,
          "end_time": "2021-07-30T20:14:00.305277",
          "exception": false,
          "start_time": "2021-07-30T20:14:00.226213",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**5. Fusion des données et correction des valeurs NaN**"
      ],
      "id": "487dbe43"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:00.465696Z",
          "iopub.status.busy": "2021-07-30T20:14:00.464736Z",
          "iopub.status.idle": "2021-07-30T20:14:00.517897Z",
          "shell.execute_reply": "2021-07-30T20:14:00.517332Z",
          "shell.execute_reply.started": "2021-07-30T11:44:30.449472Z"
        },
        "id": "636b2ed2",
        "papermill": {
          "duration": 0.134208,
          "end_time": "2021-07-30T20:14:00.518057",
          "exception": false,
          "start_time": "2021-07-30T20:14:00.383849",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "from functools import reduce\n",
        "\n",
        "df_liste = [df_SP500,df_VIX,df_US10Y,df_TYVIX]\n",
        "\n",
        "df_etude = reduce(lambda  left,right: pd.merge(left,right,on=['Date'],how='outer'), df_liste)\n",
        "df_etude"
      ],
      "id": "636b2ed2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:00.681367Z",
          "iopub.status.busy": "2021-07-30T20:14:00.680711Z",
          "iopub.status.idle": "2021-07-30T20:14:00.711491Z",
          "shell.execute_reply": "2021-07-30T20:14:00.711967Z",
          "shell.execute_reply.started": "2021-07-30T11:44:33.371530Z"
        },
        "id": "8b2316c1",
        "papermill": {
          "duration": 0.11517,
          "end_time": "2021-07-30T20:14:00.712154",
          "exception": false,
          "start_time": "2021-07-30T20:14:00.596984",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "debut = \"2011-01-10\"\n",
        "#debut = \"2015-01-01\"\n",
        "fin = \"2020-04-24\"\n",
        "\n",
        "mask = (df_etude.index >= debut) & (df_etude.index <= fin)\n",
        "df_etude = df_etude.loc[mask]\n",
        "df_etude"
      ],
      "id": "8b2316c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:00.874547Z",
          "iopub.status.busy": "2021-07-30T20:14:00.873827Z",
          "iopub.status.idle": "2021-07-30T20:14:00.881326Z",
          "shell.execute_reply": "2021-07-30T20:14:00.881841Z",
          "shell.execute_reply.started": "2021-07-30T11:44:36.177766Z"
        },
        "id": "4b2713e6",
        "papermill": {
          "duration": 0.090109,
          "end_time": "2021-07-30T20:14:00.882005",
          "exception": false,
          "start_time": "2021-07-30T20:14:00.791896",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "df_etude.isna().sum()"
      ],
      "id": "4b2713e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:01.048374Z",
          "iopub.status.busy": "2021-07-30T20:14:01.047626Z",
          "iopub.status.idle": "2021-07-30T20:14:01.066280Z",
          "shell.execute_reply": "2021-07-30T20:14:01.066750Z",
          "shell.execute_reply.started": "2021-07-30T11:44:38.638560Z"
        },
        "id": "fad6d355",
        "papermill": {
          "duration": 0.103026,
          "end_time": "2021-07-30T20:14:01.066949",
          "exception": false,
          "start_time": "2021-07-30T20:14:00.963923",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "df_etude = df_etude.interpolate(method=\"linear\")\n",
        "df_etude.isna().sum()"
      ],
      "id": "fad6d355",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18555ec6",
        "papermill": {
          "duration": 0.080009,
          "end_time": "2021-07-30T20:14:01.228528",
          "exception": false,
          "start_time": "2021-07-30T20:14:01.148519",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Déplace la cible à la fin :"
      ],
      "id": "18555ec6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:01.398208Z",
          "iopub.status.busy": "2021-07-30T20:14:01.397488Z",
          "iopub.status.idle": "2021-07-30T20:14:01.429975Z",
          "shell.execute_reply": "2021-07-30T20:14:01.429429Z",
          "shell.execute_reply.started": "2021-07-30T11:44:40.881493Z"
        },
        "id": "c4a409ed",
        "papermill": {
          "duration": 0.118967,
          "end_time": "2021-07-30T20:14:01.430145",
          "exception": false,
          "start_time": "2021-07-30T20:14:01.311178",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "col = df_etude.pop('SP500_C')\n",
        "df_etude.insert(len(df_etude.columns),\"SP500_C\",col)\n",
        "df_etude"
      ],
      "id": "c4a409ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:01.617243Z",
          "iopub.status.busy": "2021-07-30T20:14:01.616528Z",
          "iopub.status.idle": "2021-07-30T20:14:01.623131Z",
          "shell.execute_reply": "2021-07-30T20:14:01.622583Z",
          "shell.execute_reply.started": "2021-07-30T11:44:43.003003Z"
        },
        "id": "15f6fb5b",
        "papermill": {
          "duration": 0.111793,
          "end_time": "2021-07-30T20:14:01.623280",
          "exception": false,
          "start_time": "2021-07-30T20:14:01.511487",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.linspace(0,len(df_etude),len(df_etude)+1),y=df_etude['SP500_C'], line=dict(color='blue', width=1),name=\"Index\"))\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "id": "15f6fb5b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97ec5aba",
        "papermill": {
          "duration": 0.082026,
          "end_time": "2021-07-30T20:14:01.788978",
          "exception": false,
          "start_time": "2021-07-30T20:14:01.706952",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Séparation des données de test et d'entrainement"
      ],
      "id": "97ec5aba"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:01.962135Z",
          "iopub.status.busy": "2021-07-30T20:14:01.961443Z",
          "iopub.status.idle": "2021-07-30T20:14:01.967262Z",
          "shell.execute_reply": "2021-07-30T20:14:01.966689Z",
          "shell.execute_reply.started": "2021-07-30T11:44:46.427522Z"
        },
        "id": "4a908872",
        "papermill": {
          "duration": 0.095294,
          "end_time": "2021-07-30T20:14:01.967401",
          "exception": false,
          "start_time": "2021-07-30T20:14:01.872107",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Sépare les données en entrainement et tests\n",
        "pourcentage = 0.8\n",
        "temps_separation = int(len(df_etude.values) * pourcentage)\n",
        "date_separation = df_etude.index[temps_separation]\n",
        "\n",
        "serie_entrainement_X = np.array(df_etude.values[:temps_separation],dtype=np.float32)\n",
        "serie_test_X = np.array(df_etude.values[temps_separation:],dtype=np.float32)\n",
        "\n",
        "print(\"Taille de l'entrainement : %d\" %len(serie_entrainement_X))\n",
        "print(\"Taille de la validation : %d\" %len(serie_test_X))"
      ],
      "id": "4a908872",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b5a3231",
        "papermill": {
          "duration": 0.084859,
          "end_time": "2021-07-30T20:14:02.137042",
          "exception": false,
          "start_time": "2021-07-30T20:14:02.052183",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**Normalisation des données :**"
      ],
      "id": "0b5a3231"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d66f7f9",
        "papermill": {
          "duration": 0.083046,
          "end_time": "2021-07-30T20:14:02.303864",
          "exception": false,
          "start_time": "2021-07-30T20:14:02.220818",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "On normalise les données à l'aide de la fonction [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)"
      ],
      "id": "8d66f7f9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:02.491756Z",
          "iopub.status.busy": "2021-07-30T20:14:02.490948Z",
          "iopub.status.idle": "2021-07-30T20:14:02.505912Z",
          "shell.execute_reply": "2021-07-30T20:14:02.506411Z",
          "shell.execute_reply.started": "2021-07-30T11:44:49.279023Z"
        },
        "id": "d40b029d",
        "papermill": {
          "duration": 0.119143,
          "end_time": "2021-07-30T20:14:02.506609",
          "exception": false,
          "start_time": "2021-07-30T20:14:02.387466",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Constrution des séries\n",
        "serie_entrainement_X_norm = []\n",
        "serie_test_X_norm = []\n",
        "\n",
        "for i in range(0,len(df_etude.columns)):\n",
        "  serie_entrainement_X_norm.append(serie_entrainement_X[:,i])\n",
        "  serie_test_X_norm.append(serie_test_X[:,i])\n",
        "\n",
        "serie_entrainement_X_norm = tf.convert_to_tensor(serie_entrainement_X_norm)\n",
        "serie_entrainement_X_norm = tf.transpose(serie_entrainement_X_norm)\n",
        "serie_test_X_norm = tf.convert_to_tensor(serie_test_X_norm)\n",
        "serie_test_X_norm = tf.transpose(serie_test_X_norm)\n",
        "\n",
        "# Initialisaton du MinMaxScaler\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "min_max_scaler.fit(serie_entrainement_X_norm)\n",
        "\n",
        "# Normalisation des séries\n",
        "serie_entrainement_X_norm = min_max_scaler.transform(serie_entrainement_X_norm)\n",
        "serie_test_X_norm = min_max_scaler.transform(serie_test_X_norm)"
      ],
      "id": "d40b029d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:02.676205Z",
          "iopub.status.busy": "2021-07-30T20:14:02.675587Z",
          "iopub.status.idle": "2021-07-30T20:14:02.682093Z",
          "shell.execute_reply": "2021-07-30T20:14:02.681575Z",
          "shell.execute_reply.started": "2021-07-30T11:44:52.411855Z"
        },
        "id": "501a0943",
        "papermill": {
          "duration": 0.092342,
          "end_time": "2021-07-30T20:14:02.682236",
          "exception": false,
          "start_time": "2021-07-30T20:14:02.589894",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "print(serie_entrainement_X_norm.shape)\n",
        "print(serie_test_X_norm.shape)"
      ],
      "id": "501a0943",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:02.870376Z",
          "iopub.status.busy": "2021-07-30T20:14:02.869572Z",
          "iopub.status.idle": "2021-07-30T20:14:03.294838Z",
          "shell.execute_reply": "2021-07-30T20:14:03.294288Z",
          "shell.execute_reply.started": "2021-07-30T11:44:54.392941Z"
        },
        "id": "77eee3b6",
        "papermill": {
          "duration": 0.529963,
          "end_time": "2021-07-30T20:14:03.294978",
          "exception": false,
          "start_time": "2021-07-30T20:14:02.765015",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Affiche quelques séries\n",
        "fig, ax = plt.subplots(constrained_layout=True, figsize=(15,5))\n",
        "\n",
        "ax.plot(df_etude.index[:temps_separation].values,serie_entrainement_X_norm[:,0:5], label=\"X_Ent\")\n",
        "ax.plot(df_etude.index[temps_separation:].values,serie_test_X_norm[:,0:5], label=\"X_Val\")\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "id": "77eee3b6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855676e6",
        "papermill": {
          "duration": 0.087887,
          "end_time": "2021-07-30T20:14:03.471004",
          "exception": false,
          "start_time": "2021-07-30T20:14:03.383117",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Création des datasets"
      ],
      "id": "855676e6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:03.659442Z",
          "iopub.status.busy": "2021-07-30T20:14:03.658488Z",
          "iopub.status.idle": "2021-07-30T20:14:03.660277Z",
          "shell.execute_reply": "2021-07-30T20:14:03.660731Z",
          "shell.execute_reply.started": "2021-07-30T11:44:57.796139Z"
        },
        "id": "9ed3202b",
        "papermill": {
          "duration": 0.102132,
          "end_time": "2021-07-30T20:14:03.660907",
          "exception": false,
          "start_time": "2021-07-30T20:14:03.558775",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Fonction permettant de créer un dataset à partir des données de la série temporelle\n",
        "# X = {((X1_1,X1_2,...,X1_T),(X2_1,X2_2,...,X2_T),(X3_1,X3_2,...,X3_T)),\n",
        "#       (Y1,Y2,...,YT)}\n",
        "# Y = YT+1\n",
        "\n",
        "def prepare_dataset_XY(seriesX, serieY, longueur_sequence, longueur_sortie, batch_size,shift):\n",
        "  datasetX = tf.data.Dataset.from_tensor_slices(seriesX)\n",
        "  datasetX = datasetX.window(longueur_sequence+longueur_sortie, shift=shift, drop_remainder=True)\n",
        "  datasetX = datasetX.flat_map(lambda x: x.batch(longueur_sequence + longueur_sortie))\n",
        "  datasetX = datasetX.map(lambda x: (x[0:longueur_sequence][:,:]))\n",
        "  datasetX = datasetX.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "\n",
        "  datasetY = tf.data.Dataset.from_tensor_slices(serieY)\n",
        "  datasetY = datasetY.window(longueur_sequence+longueur_sortie, shift=shift, drop_remainder=True)\n",
        "  datasetY = datasetY.flat_map(lambda x: x.batch(longueur_sequence + longueur_sortie))\n",
        "  datasetY = datasetY.map(lambda x: (x[0:longueur_sequence][:,:]))\n",
        "  datasetY = datasetY.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "\n",
        "  datasetYPred = tf.data.Dataset.from_tensor_slices(serieY)\n",
        "  datasetYPred = datasetYPred.window(longueur_sequence+longueur_sortie+1, shift=shift, drop_remainder=True)\n",
        "  datasetYPred = datasetYPred.flat_map(lambda x: x.batch(longueur_sequence + longueur_sortie+1))\n",
        "  datasetYPred = datasetYPred.map(lambda x: (x[0:-1][-1:,:]))\n",
        "  datasetYPred = datasetYPred.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "\n",
        "\n",
        "  dataset = tf.data.Dataset.zip((datasetX,datasetY))\n",
        "  dataset = tf.data.Dataset.zip((dataset,datasetYPred))\n",
        "\n",
        "  return dataset"
      ],
      "id": "9ed3202b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:03.840610Z",
          "iopub.status.busy": "2021-07-30T20:14:03.839839Z",
          "iopub.status.idle": "2021-07-30T20:14:04.095049Z",
          "shell.execute_reply": "2021-07-30T20:14:04.095565Z",
          "shell.execute_reply.started": "2021-07-30T11:45:00.239805Z"
        },
        "id": "66b52604",
        "papermill": {
          "duration": 0.347399,
          "end_time": "2021-07-30T20:14:04.095760",
          "exception": false,
          "start_time": "2021-07-30T20:14:03.748361",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Définition des caractéristiques du dataset que l'on souhaite créer\n",
        "batch_size = 256                 \n",
        "longueur_sequence = 5\n",
        "longueur_sortie = 1\n",
        "shift=1\n",
        "\n",
        "# Création du dataset\n",
        "dataset = prepare_dataset_XY(serie_entrainement_X_norm[:,0:-1],serie_entrainement_X_norm[:,-1:], longueur_sequence,longueur_sortie,batch_size,shift)\n",
        "dataset_val = prepare_dataset_XY(serie_test_X_norm[:,0:-1],serie_test_X_norm[:,-1:],longueur_sequence,longueur_sortie,batch_size,shift)"
      ],
      "id": "66b52604",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:04.275332Z",
          "iopub.status.busy": "2021-07-30T20:14:04.274613Z",
          "iopub.status.idle": "2021-07-30T20:14:04.739661Z",
          "shell.execute_reply": "2021-07-30T20:14:04.739091Z",
          "shell.execute_reply.started": "2021-07-30T11:45:02.303312Z"
        },
        "id": "903ef481",
        "papermill": {
          "duration": 0.556453,
          "end_time": "2021-07-30T20:14:04.739810",
          "exception": false,
          "start_time": "2021-07-30T20:14:04.183357",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "print(len(list(dataset.as_numpy_iterator())))\n",
        "for element in dataset.take(1):\n",
        "  print(element[0][0].shape)            # ((X1),(X2),...) = ((X1_1,X1_2,...,X1_T),(X2_1,X2_2,...,X2_T),...)\n",
        "  print(element[0][1].shape)            # (Y1,Y2,...,YT)\n",
        "  print(element[1].shape)               # YT+1"
      ],
      "id": "903ef481",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:04.923092Z",
          "iopub.status.busy": "2021-07-30T20:14:04.922054Z",
          "iopub.status.idle": "2021-07-30T20:14:05.191046Z",
          "shell.execute_reply": "2021-07-30T20:14:05.190137Z",
          "shell.execute_reply.started": "2021-07-30T11:45:04.408925Z"
        },
        "id": "7909ee16",
        "papermill": {
          "duration": 0.362776,
          "end_time": "2021-07-30T20:14:05.191237",
          "exception": false,
          "start_time": "2021-07-30T20:14:04.828461",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "print(len(list(dataset_val.as_numpy_iterator())))\n",
        "for element in dataset_val.take(1):\n",
        "  print(element[0][0].shape)            # ((X1),(X2),...) = ((X1_1,X1_2,...,X1_T),(X2_1,X2_2,...,X2_T),...)\n",
        "  print(element[0][1].shape)            # Y1,Y2,...,YT\n",
        "  print(element[1].shape)               # YT+1"
      ],
      "id": "7909ee16",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90f78e27",
        "papermill": {
          "duration": 0.089694,
          "end_time": "2021-07-30T20:14:05.372496",
          "exception": false,
          "start_time": "2021-07-30T20:14:05.282802",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**3. Préparation des X/Y**"
      ],
      "id": "90f78e27"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:05.559456Z",
          "iopub.status.busy": "2021-07-30T20:14:05.558417Z",
          "iopub.status.idle": "2021-07-30T20:14:05.561772Z",
          "shell.execute_reply": "2021-07-30T20:14:05.561271Z",
          "shell.execute_reply.started": "2021-07-30T11:45:06.628378Z"
        },
        "id": "07290bd7",
        "papermill": {
          "duration": 0.101517,
          "end_time": "2021-07-30T20:14:05.561911",
          "exception": false,
          "start_time": "2021-07-30T20:14:05.460394",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def Create_train(dataset):\n",
        "  X1 = []\n",
        "  X2 = []\n",
        "\n",
        "  # Extrait les X,Y du dataset\n",
        "  x,y = tuple(zip(*dataset))              # x=43x((BS,10,3),(BS,9,1))\n",
        "                                          # y=43x(BS,1,1)\n",
        "  for i in range(len(x)):\n",
        "    X1.append(x[i][0])          \n",
        "    X2.append(x[i][1])\n",
        "\n",
        "  X1 = tf.convert_to_tensor(X1)           # (43,BS,10,3)\n",
        "  X2 = tf.convert_to_tensor(X2)           # (43,BS,9,1)\n",
        "\n",
        "  X1 = np.asarray(X1,dtype=np.float32)    # (43,BS,10,3)\n",
        "  X2 = np.asarray(X2,dtype=np.float32)    # (43,BS,10,3)   \n",
        "\n",
        "  # Recombine les données\n",
        "  y = np.asarray(y,dtype=np.float32)      # 43x(BS,1,1) => (43xBS,1,1)\n",
        "  X1 = np.reshape(X1,(X1.shape[0]*X1.shape[1],X1.shape[2],X1.shape[3]))   # (43,BS,10,3) => (43xBS,10,3)\n",
        "  X2 = np.reshape(X2,(X2.shape[0]*X2.shape[1],X2.shape[2],X2.shape[3]))   # (43,BS,9,1) => (43*BS,9,1)\n",
        "\n",
        "  x_train = [X1,X2]\n",
        "  y_train = np.asarray(tf.reshape(y,shape=(y.shape[0]*y.shape[1],longueur_sortie,y.shape[3])))\n",
        "\n",
        "  return x_train,y_train"
      ],
      "id": "07290bd7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:05.742967Z",
          "iopub.status.busy": "2021-07-30T20:14:05.741924Z",
          "iopub.status.idle": "2021-07-30T20:14:06.099014Z",
          "shell.execute_reply": "2021-07-30T20:14:06.098392Z",
          "shell.execute_reply.started": "2021-07-30T11:45:08.776012Z"
        },
        "id": "971022b8",
        "papermill": {
          "duration": 0.449964,
          "end_time": "2021-07-30T20:14:06.099173",
          "exception": false,
          "start_time": "2021-07-30T20:14:05.649209",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "x_train, y_train = Create_train(dataset)\n",
        "print(x_train[0].shape)\n",
        "print(x_train[1].shape)\n",
        "print(y_train.shape)"
      ],
      "id": "971022b8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:06.285612Z",
          "iopub.status.busy": "2021-07-30T20:14:06.284858Z",
          "iopub.status.idle": "2021-07-30T20:14:06.288546Z",
          "shell.execute_reply": "2021-07-30T20:14:06.287971Z",
          "shell.execute_reply.started": "2021-07-30T11:45:10.748534Z"
        },
        "id": "e7a0b494",
        "papermill": {
          "duration": 0.101667,
          "end_time": "2021-07-30T20:14:06.288682",
          "exception": false,
          "start_time": "2021-07-30T20:14:06.187015",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def Create_val(dataset_val):\n",
        "  X1 = []\n",
        "  X2 = []\n",
        "\n",
        "  # Extrait les X,Y du dataset\n",
        "  x,y = tuple(zip(*dataset_val))              # x=43x((BS,10,3),(BS,9,1))\n",
        "                                          # y=43x(BS,1,1)\n",
        "  for i in range(len(x)):\n",
        "    X1.append(x[i][0])          \n",
        "    X2.append(x[i][1])\n",
        "\n",
        "  X1 = tf.convert_to_tensor(X1)           # (43,BS,10,3)\n",
        "  X2 = tf.convert_to_tensor(X2)           # (43,BS,9,1)\n",
        "\n",
        "  X1 = np.asarray(X1,dtype=np.float32)    # (43,BS,10,3)\n",
        "  X2 = np.asarray(X2,dtype=np.float32)    # (43,BS,10,3)   \n",
        "\n",
        "  # Recombine les données\n",
        "  y = np.asarray(y,dtype=np.float32)      # 43x(BS,1,1) => (43xBS,1,1)\n",
        "  X1 = np.reshape(X1,(X1.shape[0]*X1.shape[1],X1.shape[2],X1.shape[3]))   # (43,BS,10,3) => (43xBS,10,3)\n",
        "  X2 = np.reshape(X2,(X2.shape[0]*X2.shape[1],X2.shape[2],X2.shape[3]))   # (43,BS,9,1) => (43*BS,9,1)\n",
        "\n",
        "  x_val = [X1,X2]\n",
        "  y_val = np.asarray(tf.reshape(y,shape=(y.shape[0]*y.shape[1],longueur_sortie,y.shape[3])))\n",
        "\n",
        "  return x_val,y_val"
      ],
      "id": "e7a0b494",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:06.470040Z",
          "iopub.status.busy": "2021-07-30T20:14:06.468914Z",
          "iopub.status.idle": "2021-07-30T20:14:06.615071Z",
          "shell.execute_reply": "2021-07-30T20:14:06.613378Z",
          "shell.execute_reply.started": "2021-07-30T11:45:13.038780Z"
        },
        "id": "afd8499a",
        "papermill": {
          "duration": 0.239045,
          "end_time": "2021-07-30T20:14:06.615229",
          "exception": false,
          "start_time": "2021-07-30T20:14:06.376184",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "x_val,y_val = Create_val(dataset_val)\n",
        "print(x_val[0].shape)\n",
        "print(x_val[1].shape)\n",
        "print(y_val.shape)"
      ],
      "id": "afd8499a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d36cd307",
        "papermill": {
          "duration": 0.088071,
          "end_time": "2021-07-30T20:14:06.791220",
          "exception": false,
          "start_time": "2021-07-30T20:14:06.703149",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Création du modèle DSTP-RNN #1"
      ],
      "id": "d36cd307"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab205b7b",
        "papermill": {
          "duration": 0.087386,
          "end_time": "2021-07-30T20:14:06.967225",
          "exception": false,
          "start_time": "2021-07-30T20:14:06.879839",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Le modèle DSTP-RNN implanté est le suivant :"
      ],
      "id": "ab205b7b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b99e3ce9",
        "papermill": {
          "duration": 0.088285,
          "end_time": "2021-07-30T20:14:07.144457",
          "exception": false,
          "start_time": "2021-07-30T20:14:07.056172",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/DSTPRNN-VueEnsemble.png?raw=true'>"
      ],
      "id": "b99e3ce9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10ada008",
        "papermill": {
          "duration": 0.089036,
          "end_time": "2021-07-30T20:14:07.321713",
          "exception": false,
          "start_time": "2021-07-30T20:14:07.232677",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**1. Création de la couche d'attention spatiale de l'étage n°1 / Phase 1**"
      ],
      "id": "10ada008"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "151e6dca",
        "papermill": {
          "duration": 0.087598,
          "end_time": "2021-07-30T20:14:07.497000",
          "exception": false,
          "start_time": "2021-07-30T20:14:07.409402",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "On commence par créer la couche permettant de calculer le score. Cette fonction calcule le score de l'encodeur, c'est-à-dire le score à attribuer à chaque série d'entrée.  \n",
        "Cette fonction est appellée par l'encodeur à l'aide de la méthode TimeDistribued de Keras, pour chaque série d'entrée."
      ],
      "id": "151e6dca"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "584e9f1f",
        "papermill": {
          "duration": 0.089164,
          "end_time": "2021-07-30T20:14:07.674127",
          "exception": false,
          "start_time": "2021-07-30T20:14:07.584963",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/CalculScore__.png?raw=true' width=900>"
      ],
      "id": "584e9f1f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:07.867324Z",
          "iopub.status.busy": "2021-07-30T20:14:07.866509Z",
          "iopub.status.idle": "2021-07-30T20:14:07.869285Z",
          "shell.execute_reply": "2021-07-30T20:14:07.869755Z",
          "shell.execute_reply.started": "2021-07-30T11:45:30.630709Z"
        },
        "id": "a1570539",
        "papermill": {
          "duration": 0.107777,
          "end_time": "2021-07-30T20:14:07.869945",
          "exception": false,
          "start_time": "2021-07-30T20:14:07.762168",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class CalculScores_Encodeur_Phase1(tf.keras.layers.Layer):\n",
        "  def __init__(self, dim_LSTM_enc_P1):\n",
        "    self.dim_LSTM_enc_P1 = dim_LSTM_enc_P1\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.Wf = self.add_weight(shape=(input_shape[1],2*self.dim_LSTM_enc_P1),initializer=\"normal\",name=\"Wf\")     # (Tin, 2x#LSTM_encP1)\n",
        "    self.Uf = self.add_weight(shape=(input_shape[1],input_shape[1]),initializer=\"normal\",name=\"Uf\")             # (Tin, Tin)\n",
        "    self.bf = self.add_weight(shape=(input_shape[1],1),initializer=\"normal\",name=\"bf\")                          # (Tin, 1)\n",
        "    self.vf = self.add_weight(shape=(input_shape[1],1),initializer=\"normal\",name=\"vf\")                          # (Tin, 1)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "    \n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return (input_shape[0], 1)\n",
        "\n",
        "  #     hidd_state:     hidden_state        : (batch_size,#LSTM_encP1)\n",
        "  #     cell_state:     Cell state          : (batch_size,#LSTM_encP1)]\n",
        "\n",
        "  def SetStates(self,hidd_state, cell_state):\n",
        "    self.hidd_state = hidd_state\n",
        "    self.cell_state = cell_state\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:          Entrées X           : (batch_size,Tin,1)\n",
        "  # Sorties :\n",
        "  #     score:          Score               : (batch_size,1,1)\n",
        "\n",
        "  def call(self, input):\n",
        "    if self.hidd_state is not None:\n",
        "        hs = tf.keras.layers.concatenate([self.hidd_state,self.cell_state],axis=1)        # (batch_size,2x#LSTM_encP1)\n",
        "        hs = tf.expand_dims(hs,-1)                                              # (batch_size,2x#LSTM_encP1) => (batch_size,2#LSTM_encP1,1)\n",
        "        e = tf.matmul(self.Wf,hs)                                               # (Tin,2x#LSTM_encP1)x(batch_size,2x#LSTM_encP1,1) = (batch_size,Tin,1)\n",
        "        e = e + tf.matmul(self.Uf,input)                                        # (Tin,Tin)x(batch_size,Tin,1) = (batch_size,Tin,1)\n",
        "        e = e + self.bf                                                         # (batch_size,Tin,1)\n",
        "    else:\n",
        "        e = tf.matmul(self.Uf,input)                                            # (Tin,Tin)x(batch_size,Tin,1) = (batch_size,Tin,1)\n",
        "        e = e + self.bf                                                         # (batch_size,Tin,1)\n",
        "    e = K.tanh(e)\n",
        "    score = tf.matmul(tf.transpose(self.vf),e)                                  # (1,Tin)x(batch_size,Tin,1) = (batch_size,1,1)\n",
        "    return tf.squeeze(score,-1)                                                 # (batch_size,1)"
      ],
      "id": "a1570539",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba240f50",
        "papermill": {
          "duration": 0.088351,
          "end_time": "2021-07-30T20:14:08.048950",
          "exception": false,
          "start_time": "2021-07-30T20:14:07.960599",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Puis maintenant la couche d'attention :"
      ],
      "id": "ba240f50"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b05ee56",
        "papermill": {
          "duration": 0.089569,
          "end_time": "2021-07-30T20:14:08.227422",
          "exception": false,
          "start_time": "2021-07-30T20:14:08.137853",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/EncodeurPhase1__.png?raw=true' width=900>"
      ],
      "id": "6b05ee56"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:08.421512Z",
          "iopub.status.busy": "2021-07-30T20:14:08.420778Z",
          "iopub.status.idle": "2021-07-30T20:14:08.424139Z",
          "shell.execute_reply": "2021-07-30T20:14:08.423610Z",
          "shell.execute_reply.started": "2021-07-30T11:45:34.081432Z"
        },
        "id": "61510e2d",
        "papermill": {
          "duration": 0.105672,
          "end_time": "2021-07-30T20:14:08.424285",
          "exception": false,
          "start_time": "2021-07-30T20:14:08.318613",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class Encodeur_Phase1(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, dim_LSTM_enc_P1, regul=0.0, drop=0.0):\n",
        "    self.regul = regul\n",
        "    self.dim_LSTM_enc_P1 = dim_LSTM_enc_P1          # Dimension des vecteurs cachés\n",
        "    self.drop = drop\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.couche_LSTM = tf.keras.layers.LSTM(self.dim_LSTM_enc_P1,kernel_regularizer=tf.keras.regularizers.l2(self.regul),return_sequences=False,return_state=True,dropout=self.drop,recurrent_dropout=self.drop, name=\"LSTM_Encodeur\")\n",
        "    self.CalculScores_Encodeur_Phase1 = CalculScores_Encodeur_Phase1(dim_LSTM_enc_P1=self.dim_LSTM_enc_P1)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:          Entrées X           : (batch_size,Tin,#dim)\n",
        "  #     hidd_state:     hidden_state        : (batch_size,#LSTM_encP1)\n",
        "  #     cell_state:     Cell state          : (batch_size,#LSTM_encP1)]\n",
        "  #     index:          index série         : (1)\n",
        "  # Sorties :\n",
        "  #     out_hid : Sortie vecteur caché      : (batch_size,#LSTM_encP1)\n",
        "  #     out_cell: Sortie cell state         : (btach_size,#LSTM_encP1)\n",
        "  #     x_tilda : Coupe temporelle pondérée : (batch_size,1,#dim)\n",
        "\n",
        "  def call(self, input, hidd_state, cell_state, index):\n",
        "    # Calcul des scores\n",
        "    input_TD = tf.transpose(input,perm=[0,2,1])                               # (batch_size,Tin,#dim) => (batch_size,#dim,Tin)\n",
        "    input_TD = tf.expand_dims(input_TD,axis=-1)                               # (batch_size,#dim,Tin) => (batch_size,#dim,Tin,1)\n",
        "    self.CalculScores_Encodeur_Phase1.SetStates(hidd_state,cell_state)\n",
        "    a = tf.keras.layers.TimeDistributed(\n",
        "        self.CalculScores_Encodeur_Phase1)(input_TD)                          # (batch_size,#dim,Tin,1) : Timestep=#dim\n",
        "                                                                              # (batch_size,Tin,1) envoyé #dim fois en //\n",
        "                                                                              # (batch_size,#dim,1) retourné\n",
        "    # Normalisation des scores alpha\n",
        "    a = tf.keras.activations.softmax(a,axis=1)                                # (batch_size,#dim,1)\n",
        "\n",
        "    # Applique les poids normalisés à la coupe temporelle des séries exogènes\n",
        "    x_tilda = tf.multiply(tf.expand_dims(input[:,index,:],-1),a)              # (batch_size,#dim,1) _x_ (batch_size,#dim,1) = (batch_size,#dim,1)\n",
        "    x_tilda = tf.transpose(x_tilda,perm=[0,2,1])                              # (batch_size,1,#dim)\n",
        "\n",
        "    # Applique x_tilda à la cellule LSTM\n",
        "    x_tilda = tf.transpose(x_tilda,perm=[0,2,1])                              # (batch_size,#dim,1)\n",
        "    out_dec, out_hid, out_cell = self.couche_LSTM(x_tilda)                    # out_dec et out_cell : (batch_size,#LSTM_encP1)\n",
        "    x_tilda = tf.transpose(x_tilda,perm=[0,2,1])                              # (batch_size,1,#dim)\n",
        "\n",
        "    return out_hid, out_cell, x_tilda\n"
      ],
      "id": "61510e2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bb8bf63",
        "papermill": {
          "duration": 0.088557,
          "end_time": "2021-07-30T20:14:08.601150",
          "exception": false,
          "start_time": "2021-07-30T20:14:08.512593",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**2. Création de la couche d'attention spatiale de l'étage n°1 / Phase 2**"
      ],
      "id": "9bb8bf63"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6879d40d",
        "papermill": {
          "duration": 0.088717,
          "end_time": "2021-07-30T20:14:08.806084",
          "exception": false,
          "start_time": "2021-07-30T20:14:08.717367",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/EncodeurPhase2_CalculScore__.png?raw=true'>"
      ],
      "id": "6879d40d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4de35f1a",
        "papermill": {
          "duration": 0.088523,
          "end_time": "2021-07-30T20:14:08.984702",
          "exception": false,
          "start_time": "2021-07-30T20:14:08.896179",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "On commence par créer le calcul  du score :"
      ],
      "id": "4de35f1a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db898f95",
        "papermill": {
          "duration": 0.090051,
          "end_time": "2021-07-30T20:14:09.162825",
          "exception": false,
          "start_time": "2021-07-30T20:14:09.072774",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/EncodeurPhase2_CalculScore2__.png?raw=true'>"
      ],
      "id": "db898f95"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:09.356153Z",
          "iopub.status.busy": "2021-07-30T20:14:09.355199Z",
          "iopub.status.idle": "2021-07-30T20:14:09.359948Z",
          "shell.execute_reply": "2021-07-30T20:14:09.359302Z",
          "shell.execute_reply.started": "2021-07-30T11:45:39.821979Z"
        },
        "id": "69f48540",
        "papermill": {
          "duration": 0.10796,
          "end_time": "2021-07-30T20:14:09.360115",
          "exception": false,
          "start_time": "2021-07-30T20:14:09.252155",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class CalculScores_Encodeur_Phase2(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, dim_LSTM_encP2):\n",
        "    self.dim_LSTM_encP2 = dim_LSTM_encP2\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.Ws = self.add_weight(shape=(input_shape[1],2*self.dim_LSTM_encP2),initializer=\"normal\",name=\"Ws\")    # (Tin, 2x#LSTM_encP2)\n",
        "    self.Us = self.add_weight(shape=(input_shape[1],input_shape[1]),initializer=\"normal\",name=\"Us\")     # (Tin, Tin)\n",
        "    self.bs = self.add_weight(shape=(input_shape[1],1),initializer=\"normal\",name=\"bs\")                  # (Tin, 1)\n",
        "    self.vs = self.add_weight(shape=(input_shape[1],1),initializer=\"normal\",name=\"vs\")                  # (Tin, 1)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "    \n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return (input_shape[0], 1)\n",
        "\n",
        "  #     hidd_state:     hidden_state        : (batch_size,#LSTM_encP2)\n",
        "  #     cell_state:     Cell state          : (batch_size,#LSTM_encP2)]\n",
        "\n",
        "  def SetStates(self,hidd_state, cell_state):\n",
        "    self.hidd_state = hidd_state\n",
        "    self.cell_state = cell_state\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:          Entrées Z           : (batch_size,Tin,1)\n",
        "  # Sorties :\n",
        "  #     score:          Score               : (batch_size,1,1)\n",
        "\n",
        "  def call(self, input):\n",
        "    if self.hidd_state is not None:\n",
        "        hs = tf.keras.layers.concatenate([self.hidd_state,self.cell_state],axis=1)        # (batch_size,2x#LSTM_encP2)\n",
        "        hs = tf.expand_dims(hs,-1)                                              # (batch_size,2x#LSTM_encP2) => (batch_size,2#LSTM_encP2,1)\n",
        "        e = tf.matmul(self.Ws,hs)                                               # (Tin,2x#LSTM_encP2)x(batch_size,2x#LSTM_encP2,1) = (batch_size,Tin,1)\n",
        "        e = e + tf.matmul(self.Us,input)                                        # (Tin,Tin)x(batch_size,Tin,1) = (batch_size,Tin,1)\n",
        "        e = e + self.bs                                                         # (batch_size,Tin,1)\n",
        "    else:\n",
        "        e = tf.matmul(self.Us,input)                                            # (Tin,Tin)x(batch_size,Tin,1) = (batch_size,Tin,1)\n",
        "        e = e + self.bs                                                         # (batch_size,Tin,1)\n",
        "    e = K.tanh(e)\n",
        "    score = tf.matmul(tf.transpose(self.vs),e)                                  # (1,Tin)x(batch_size,Tin,1) = (batch_size,1,1)\n",
        "    return tf.squeeze(score,-1)                                                 # (batch_size,1)"
      ],
      "id": "69f48540",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2f31f7e",
        "papermill": {
          "duration": 0.087719,
          "end_time": "2021-07-30T20:14:09.536667",
          "exception": false,
          "start_time": "2021-07-30T20:14:09.448948",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Puis maintenant la couche d'attention :"
      ],
      "id": "e2f31f7e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d2aa7c5",
        "papermill": {
          "duration": 0.088803,
          "end_time": "2021-07-30T20:14:09.714937",
          "exception": false,
          "start_time": "2021-07-30T20:14:09.626134",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/EncodeurPhase22__.png?raw=true'>"
      ],
      "id": "9d2aa7c5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:09.906897Z",
          "iopub.status.busy": "2021-07-30T20:14:09.906116Z",
          "iopub.status.idle": "2021-07-30T20:14:09.909245Z",
          "shell.execute_reply": "2021-07-30T20:14:09.908599Z",
          "shell.execute_reply.started": "2021-07-30T11:45:43.897267Z"
        },
        "id": "f60a1e0d",
        "papermill": {
          "duration": 0.10593,
          "end_time": "2021-07-30T20:14:09.909409",
          "exception": false,
          "start_time": "2021-07-30T20:14:09.803479",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class Encodeur_Phase2(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, dim_LSTM_encP2, regul=0.0, drop=0.0):\n",
        "    self.regul = regul\n",
        "    self.dim_LSTM_encP2 = dim_LSTM_encP2          # Dimension des vecteurs cachés\n",
        "    self.drop = drop\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.couche_LSTM = tf.keras.layers.LSTM(self.dim_LSTM_encP2,kernel_regularizer=tf.keras.regularizers.l2(self.regul),return_sequences=False,return_state=True,dropout=self.drop,recurrent_dropout=self.drop, name=\"LSTM_Encodeur\")\n",
        "    self.CalculScores_Encodeur_Phase2 = CalculScores_Encodeur_Phase2(dim_LSTM_encP2=self.dim_LSTM_encP2)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:          Entrées Z           : (batch_size,Tin,#dim+1)\n",
        "  #     hidd_state:     hidden_state        : (batch_size,#LSTM_encP2)\n",
        "  #     cell_state:     Cell state          : (batch_size,#LSTM_encP2)]\n",
        "  #     index:          index série         : (1)\n",
        "  # Sorties :\n",
        "  #     out_hid : Sortie vecteur caché      : (batch_size,#LSTM_encP2)\n",
        "  #     out_cell: Sortie cell state         : (btach_size,#LSTM_encP2)\n",
        "\n",
        "  def call(self, input, hidd_state, cell_state, index):\n",
        "    # Calcul des scores\n",
        "    input_TD = tf.transpose(input,perm=[0,2,1])                               # (batch_size,Tin,#dim+1) => (batch_size,#dim+1,Tin)\n",
        "    input_TD = tf.expand_dims(input_TD,axis=-1)                               # (batch_size,#dim+1,Tin) => (batch_size,#dim+1,Tin,1)\n",
        "    self.CalculScores_Encodeur_Phase2.SetStates(hidd_state,cell_state)\n",
        "    b = tf.keras.layers.TimeDistributed(\n",
        "        self.CalculScores_Encodeur_Phase2)(input_TD)                          # (batch_size,#dim+1,Tin,1) : Timestep=#dim+1\n",
        "                                                                              # (batch_size,Tin,1) envoyé #dim+1 fois en //\n",
        "                                                                              # (batch_size,#dim+1,1) retourné\n",
        "    # Normalisation des scores beta\n",
        "    b = tf.keras.activations.softmax(b,axis=1)                                # (batch_size,#dim+1,1)\n",
        "\n",
        "    # Applique les poids normalisés à la série\n",
        "    z_tilda = tf.multiply(tf.expand_dims(input[:,index,:],-1),b)              # (batch_size,#dim+1,1) _x_ (batch_size,#dim+1,1) = (batch_size,#dim+1,1)\n",
        "    z_tilda = tf.transpose(z_tilda,perm=[0,2,1])                              # (batch_size,1,#dim+1)\n",
        "\n",
        "    # Applique z_tilda à la cellule LSTM\n",
        "    z_tilda = tf.transpose(z_tilda,perm=[0,2,1])                              # (batch_size,#dim+1,1)\n",
        "    out_dec, out_hid, out_cell = self.couche_LSTM(z_tilda)                    # out_dec et out_cell : (batch_size,#LSTM_encP2)\n",
        "    z_tilda = tf.transpose(z_tilda,perm=[0,2,1])                              # (batch_size,1,#dim+1)\n",
        "\n",
        "    return out_hid, out_cell\n"
      ],
      "id": "f60a1e0d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d52ae4c",
        "papermill": {
          "duration": 0.089918,
          "end_time": "2021-07-30T20:14:10.088757",
          "exception": false,
          "start_time": "2021-07-30T20:14:09.998839",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**3. Création de la couche d'attention du décodeur**"
      ],
      "id": "5d52ae4c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8c7435c",
        "papermill": {
          "duration": 0.087772,
          "end_time": "2021-07-30T20:14:10.265052",
          "exception": false,
          "start_time": "2021-07-30T20:14:10.177280",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/CalculScoreDecodeur3.png?raw=true'>"
      ],
      "id": "b8c7435c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f312e30",
        "papermill": {
          "duration": 0.089966,
          "end_time": "2021-07-30T20:14:10.445303",
          "exception": false,
          "start_time": "2021-07-30T20:14:10.355337",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "On commence par créer la couche de calcul du score du décodeur.  \n",
        "Cette fonction calcule le score du décodeur, c'est-à-dire le score à attribuer à chaque hidden-state en sortie de l'encodeur.  \n",
        "Cette fonction est appellée par la couche d'attention temporelle du décodeur à l'aide de la méthode TimeDistribued de Keras."
      ],
      "id": "6f312e30"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "add1b19c",
        "papermill": {
          "duration": 0.088299,
          "end_time": "2021-07-30T20:14:10.623053",
          "exception": false,
          "start_time": "2021-07-30T20:14:10.534754",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/CalculScoreDecodeur4.png?raw=true'>"
      ],
      "id": "add1b19c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:10.814774Z",
          "iopub.status.busy": "2021-07-30T20:14:10.813935Z",
          "iopub.status.idle": "2021-07-30T20:14:10.817241Z",
          "shell.execute_reply": "2021-07-30T20:14:10.816503Z",
          "shell.execute_reply.started": "2021-07-30T11:45:48.833425Z"
        },
        "id": "4bbd4b54",
        "papermill": {
          "duration": 0.105971,
          "end_time": "2021-07-30T20:14:10.817388",
          "exception": false,
          "start_time": "2021-07-30T20:14:10.711417",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class CalculScores_Decodeur(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self,dim_LSTM_encP2,dim_LSTM_dec):\n",
        "    self.dim_LSTM_encP2 = dim_LSTM_encP2        # Dimension des vecteurs cachés provenant de l'encodeur\n",
        "    self.dim_LSTM_dec = dim_LSTM_dec            # Dimension des vecteurs cachés du décodeur\n",
        "\n",
        "    super().__init__()                  # Appel du __init__() de la classe Layer\n",
        "  \n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.Wd = self.add_weight(shape=(self.dim_LSTM_dec,2*self.dim_LSTM_dec),initializer=\"normal\",name=\"Wd\")     # (#dim_LSTM_dec, 2x#dim_LSTM_dec)\n",
        "    self.Ud = self.add_weight(shape=(self.dim_LSTM_dec,self.dim_LSTM_encP2),initializer=\"normal\",name=\"Ud\")     # (#dim_LSTM_dec, #dim_LSTM_encP2)\n",
        "    self.bd = self.add_weight(shape=(self.dim_LSTM_dec,1),initializer=\"normal\",name=\"bd\")                       # (#dim_LSTM_dec, 1)\n",
        "    self.vd = self.add_weight(shape=(self.dim_LSTM_dec,1),initializer=\"normal\",name=\"vd\")                       # (#dim_LSTM_dec, 1)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return (input_shape[0], 1)\n",
        "\n",
        "\n",
        "  #     hidd_state:     hidden_state        : (batch_size,#dim_LSTM_dec)\n",
        "  #     cell_state:     Cell state          : (batch_size,#dim_LSTM_dec)\n",
        "\n",
        "  def SetStates(self,hidd_state, cell_state):\n",
        "    self.hidd_state = hidd_state\n",
        "    self.cell_state = cell_state\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:        Entrée score décodeur : (batch_size,#LSTM_encP1)\n",
        "  # Sorties :\n",
        "  #     score:        score                 : (batch_size,1)\n",
        "\n",
        "  def call(self,input):\n",
        "    input = tf.expand_dims(input,-1)\n",
        "    if self.hidd_state is not None:\n",
        "        hs = tf.keras.layers.concatenate([self.hidd_state,self.cell_state],axis=1)        # (batch_size,2x#dim_LSTM_dec)\n",
        "        hs = tf.expand_dims(hs,-1)                                              # (batch_size,2x#dim_LSTM_dec) => (batch_size,2#dim_LSTM_dec,1)\n",
        "        e = tf.matmul(self.Wd,hs)                                               # (#dim_LSTM_dec,2x#dim_LSTM_dec)x(batch_size,2x#dim_LSTM_dec,1) = (batch_size,#dim_LSTM_dec,1)\n",
        "        e = e + tf.matmul(self.Ud,input)                                        # (#dim_LSTM_dec,#dim_LSTM_encP2)x(batch_size,#LSTM_encP1,1) = (batch_size,#dim_LSTM_dec,1)\n",
        "        e = e + self.bd                                                         # (batch_size,#dim_LSTM_dec,1)\n",
        "    else:\n",
        "        e = tf.matmul(self.Ud,input)                                            # (#dim_LSTM_dec,#dim_LSTM_encP2)x(batch_size,#LSTM_encP1,1) = (batch_size,#dim_LSTM_dec,1)\n",
        "        e = e + self.bd                                                         # (batch_size,#dim_LSTM_dec,1)\n",
        "    e = K.tanh(e)\n",
        "    score = tf.matmul(tf.transpose(self.vd),e)                                  # (1,#dim_LSTM_dec)x(batch_size,#dim_LSTM_dec,1) = (batch_size,1,1)\n",
        "    score = tf.squeeze(score,-1)                                                # (batch_size,1)\n",
        "    return score"
      ],
      "id": "4bbd4b54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fd01c5f",
        "papermill": {
          "duration": 0.088964,
          "end_time": "2021-07-30T20:14:10.996069",
          "exception": false,
          "start_time": "2021-07-30T20:14:10.907105",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Puis maintenant la couche d'attention :"
      ],
      "id": "7fd01c5f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6d5c5ed",
        "papermill": {
          "duration": 0.08872,
          "end_time": "2021-07-30T20:14:11.174015",
          "exception": false,
          "start_time": "2021-07-30T20:14:11.085295",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/CalculScoreDecodeur5.png?raw=true'>"
      ],
      "id": "e6d5c5ed"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:11.355128Z",
          "iopub.status.busy": "2021-07-30T20:14:11.354403Z",
          "iopub.status.idle": "2021-07-30T20:14:11.363898Z",
          "shell.execute_reply": "2021-07-30T20:14:11.364447Z",
          "shell.execute_reply.started": "2021-07-30T11:45:52.226115Z"
        },
        "id": "ede13b5c",
        "papermill": {
          "duration": 0.102407,
          "end_time": "2021-07-30T20:14:11.364631",
          "exception": false,
          "start_time": "2021-07-30T20:14:11.262224",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class CalculAttention_Decodeur(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, dim_LSTM_encP2, dim_LSTM_dec):\n",
        "    self.dim_LSTM_encP2 = dim_LSTM_encP2          # Dimension des vecteurs cachés de l'encodeur\n",
        "    self.dim_LSTM_dec = dim_LSTM_dec              # dimension vecteurs cachés décodeur\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.couche_CalculScores_Decodeur = CalculScores_Decodeur(dim_LSTM_encP2=self.dim_LSTM_encP2,dim_LSTM_dec=self.dim_LSTM_dec)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  #     hidd_state:     hidden_state        : (batch_size,#LSTM_dec)\n",
        "  #     cell_state:     Cell state          : (batch_size,#LSTM_dec)\n",
        "\n",
        "  def SetStates(self,hidd_state, cell_state):\n",
        "    self.hidd_state = hidd_state\n",
        "    self.cell_state = cell_state\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:          Entrées X           : (batch_size,Tin,#LSTM_encP2)\n",
        "  # Sorties :\n",
        "  #     vect_contexte   Vecteur Contexte    : (batch_size,1,#LSTM_encP2)\n",
        "\n",
        "  def call(self, input):\n",
        "    # Calcul des scores\n",
        "    self.couche_CalculScores_Decodeur.SetStates(self.hidd_state,self.cell_state)\n",
        "    g = tf.keras.layers.TimeDistributed(\n",
        "        self.couche_CalculScores_Decodeur)(input)                             # (batch_size,Tin,#LSTM_encP2) : Timestep=Tin\n",
        "                                                                              # (batch_size,#LSTM_encP2) envoyé Tin fois en //\n",
        "                                                                              # (batch_size,Tin,1) retourné\n",
        "    # Normalisation des scores gama\n",
        "    g = tf.keras.activations.softmax(g,axis=1)                                # (batch_size,Tin,1)\n",
        "\n",
        "    # Calcul du vecteur contexte\n",
        "    C = tf.multiply(input,g)        # (batch_size,Tin,#LSTM_encP2)_x_(batch_size,Tin,1) = (batch_size,Tin,#LSTM_encP2)\n",
        "    C = K.sum(C,axis=1)             # (batch_size,#LSTM_encP2)\n",
        "    C = tf.expand_dims(C,1)         # (batch_size,1,#LSTM_encP2)\n",
        "    return C\n"
      ],
      "id": "ede13b5c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4fb194f",
        "papermill": {
          "duration": 0.088053,
          "end_time": "2021-07-30T20:14:11.540928",
          "exception": false,
          "start_time": "2021-07-30T20:14:11.452875",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**4. Création de la couche de décodeur**"
      ],
      "id": "c4fb194f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36956af0",
        "papermill": {
          "duration": 0.087812,
          "end_time": "2021-07-30T20:14:11.721533",
          "exception": false,
          "start_time": "2021-07-30T20:14:11.633721",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/CoucheDecodeurAll.png?raw=true'>"
      ],
      "id": "36956af0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:11.901859Z",
          "iopub.status.busy": "2021-07-30T20:14:11.901121Z",
          "iopub.status.idle": "2021-07-30T20:14:11.914479Z",
          "shell.execute_reply": "2021-07-30T20:14:11.915052Z",
          "shell.execute_reply.started": "2021-07-30T11:45:55.309155Z"
        },
        "id": "c0070d80",
        "papermill": {
          "duration": 0.105404,
          "end_time": "2021-07-30T20:14:11.915228",
          "exception": false,
          "start_time": "2021-07-30T20:14:11.809824",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class Decodeur(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self,dim_LSTM_encP2, dim_LSTM_dec, regul=0.0, drop=0.0):\n",
        "    self.regul = regul\n",
        "    self.dim_LSTM_encP2 = dim_LSTM_encP2            # Dimension des vecteurs cachés\n",
        "    self.dim_LSTM_dec = dim_LSTM_dec\n",
        "    self.drop = drop\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.couche_Attention_Decodeur = CalculAttention_Decodeur(dim_LSTM_encP2=self.dim_LSTM_encP2,dim_LSTM_dec=self.dim_LSTM_dec)\n",
        "    self.couche_LSTM = tf.keras.layers.LSTM(self.dim_LSTM_dec,kernel_regularizer=tf.keras.regularizers.l2(self.regul),return_sequences=False,return_state=True,dropout=self.drop,recurrent_dropout=self.drop, name=\"LSTM_Decodeur\")\n",
        "    self.W = self.add_weight(shape=(self.dim_LSTM_encP2+1,1),initializer=\"normal\",name=\"W\")                   # (#dim_LSTM_encP2+1, 1)\n",
        "    self.b = self.add_weight(shape=(1,1),initializer=\"normal\",name=\"b\")                                       # (1, 1)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:        Entrée décodeur       : (batch_size,Tin,#LSTM_encP2)\n",
        "  #     Y:            Yt                    : (batch_size,1,1)\n",
        "  #     hid_state:    hidden state          : (batch_size,#LSTM_dec)\n",
        "  #     cell_state:   cell_state            : (batch_size,#LSTM_dec)\n",
        "  # Sorties :\n",
        "  #     out_hid :     hidden_state          : (batch_size,#LSTM_dec)\n",
        "  #     out_cell :    cell_state            : (batch_size,#LSTM_dec)\n",
        "  #     v_contexte:   vecteur contexte      : (batch_size,#LSTM_encP2)\n",
        "\n",
        "  def call(self,input,Y,hid_state,cell_state):\n",
        "    # Calcul du vecteur contexte\n",
        "    self.couche_Attention_Decodeur.SetStates(hid_state,cell_state)\n",
        "    C = self.couche_Attention_Decodeur(input)           # (batch_size,1,#LSTM_encP2)\n",
        "\n",
        "    # Calcul de Y_tilda\n",
        "    add = tf.keras.layers.concatenate([Y,C],axis=2)     # (batch_size,1,#LSTM_encP2+1)\n",
        "    add = tf.transpose(add,perm=[0,2,1])                # (batch_size,#LSTM_encP2+1,1)\n",
        "    Y_tilda = tf.matmul(tf.transpose(self.W),add)       # (1,#LSTM_encP2+1) x (batch_size,#LSTM_encP2+1,1) = (batch_size,1,1)\n",
        "    Y_tilda = Y_tilda + self.b\n",
        "\n",
        "    # Calcul des hidden state et cell state\n",
        "    if hid_state is not None:\n",
        "      out_, out_hid, out_cell = self.couche_LSTM(Y_tilda,initial_state=[hid_state,cell_state])\n",
        "    else:\n",
        "      out_, out_hid, out_cell = self.couche_LSTM(Y_tilda)\n",
        "\n",
        "    return out_hid,out_cell, C"
      ],
      "id": "c0070d80",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a0efc71",
        "papermill": {
          "duration": 0.088445,
          "end_time": "2021-07-30T20:14:12.092758",
          "exception": false,
          "start_time": "2021-07-30T20:14:12.004313",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**5. Création de la couche de décodeur**"
      ],
      "id": "2a0efc71"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fffae7b",
        "papermill": {
          "duration": 0.141462,
          "end_time": "2021-07-30T20:14:12.341472",
          "exception": false,
          "start_time": "2021-07-30T20:14:12.200010",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Il ne reste plus qu'à créer l'architecture complète et d'ajouter l'estimation de la sortie :"
      ],
      "id": "0fffae7b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8da07451",
        "papermill": {
          "duration": 0.088245,
          "end_time": "2021-07-30T20:14:12.518702",
          "exception": false,
          "start_time": "2021-07-30T20:14:12.430457",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/DSTPRNN-VueEnsemble.png?raw=true'>"
      ],
      "id": "8da07451"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "322404ae",
        "papermill": {
          "duration": 0.088078,
          "end_time": "2021-07-30T20:14:12.696388",
          "exception": false,
          "start_time": "2021-07-30T20:14:12.608310",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Prédictions des valeurs multi-step :"
      ],
      "id": "322404ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c475ef18",
        "papermill": {
          "duration": 0.088071,
          "end_time": "2021-07-30T20:14:12.872722",
          "exception": false,
          "start_time": "2021-07-30T20:14:12.784651",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<img src='https://github.com/AlexandreBourrieau/FICHIERS/blob/main/Series_Temporelles/Seq2SeqMulti/images/DSTPRNNPredictions__.png?raw=true' width=600>"
      ],
      "id": "c475ef18"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:13.070605Z",
          "iopub.status.busy": "2021-07-30T20:14:13.060003Z",
          "iopub.status.idle": "2021-07-30T20:14:13.078111Z",
          "shell.execute_reply": "2021-07-30T20:14:13.077540Z",
          "shell.execute_reply.started": "2021-07-30T11:45:59.094745Z"
        },
        "id": "621ce569",
        "papermill": {
          "duration": 0.116428,
          "end_time": "2021-07-30T20:14:13.078265",
          "exception": false,
          "start_time": "2021-07-30T20:14:12.961837",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class Net_DSTPRNN(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self,encodeur_phase1, encodeur_phase2,decodeur,longueur_sequence, longueur_sortie, dim_LSTM_dec, dim_LSTM_encP2, regul=0.0, drop = 0.0):\n",
        "    self.encodeur_phase1 = encodeur_phase1\n",
        "    self.encodeur_phase2 = encodeur_phase2\n",
        "    self.decodeur = decodeur\n",
        "    self.longueur_sequence = longueur_sequence\n",
        "    self.longueur_sortie = longueur_sortie\n",
        "    self.regul = regul\n",
        "    self.drop = drop\n",
        "    self.dim_LSTM_dec = dim_LSTM_dec\n",
        "    self.dim_LSTM_encP2 = dim_LSTM_encP2\n",
        "    super().__init__()                # Appel du __init__() de la classe Layer\n",
        "  \n",
        "\n",
        "  def build(self,input_shape):\n",
        "    self.Wy = self.add_weight(shape=(self.longueur_sortie,self.dim_LSTM_dec,self.dim_LSTM_dec+self.dim_LSTM_encP2),initializer=\"normal\",name=\"Wy\")        # (longueur_sortie,#LSTM_dec, #LSTM_dec+#LSTM_encP2)\n",
        "    self.by = self.add_weight(shape=(self.longueur_sortie,self.dim_LSTM_dec,1),initializer=\"normal\",name=\"by\")                                            # (longueur_sortie,#LSTM_dec, 1)\n",
        "    self.vy = self.add_weight(shape=(self.longueur_sortie,self.dim_LSTM_dec,1),initializer=\"normal\",name=\"vy\")                                            # (longueur_sortie,#LSTM_dec,1)\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  # Entrées :\n",
        "  #     input:          Entrées X           : (batch_size,Tin,#dim)\n",
        "  #     output_seq:     Sortie séquence Y   : (batch_size,Tin,1)\n",
        "  # Sorties :\n",
        "  #     sortie:         Prédiction Y        : (batch_size,longueur_sortie,1)\n",
        "\n",
        "  def call(self,input,output_seq):\n",
        "    # Phase n°1 d'encodage\n",
        "    # Calcul les représentations spatiales pondérées\n",
        "    # des coupes temporelles des séries exogènes en entrée\n",
        "    # x_tilda\n",
        "    x_tilda = []\n",
        "    hid_state = None\n",
        "    cell_state = None\n",
        "    for i in range(input.shape[1]):\n",
        "      hid_state, cell_state, x_t = self.encodeur_phase1(input,hid_state,cell_state,i)\n",
        "      x_t = tf.squeeze(x_t,1)                     # (batch_size,1,#dim) => (batch_size,#dim)\n",
        "      x_tilda.append(x_t)                         # (batch_size,#dim)\n",
        "    x_tilda = tf.convert_to_tensor(x_tilda)       # (Tin,batch_size,#dim)\n",
        "    x_tilda = tf.transpose(x_tilda,perm=[1,0,2])  # (batch_size,Tin,#dim)\n",
        "\n",
        "    # Concaténation des sorties de la phase 1 avec la série cible\n",
        "    Z = []\n",
        "\n",
        "    for i in range(input.shape[1]):\n",
        "      z = tf.keras.layers.concatenate([x_tilda[:,i,:],                 # (batch_size,#dim+1)\n",
        "                                       output_seq[:,i,:]],axis=1)\n",
        "      Z.append(z)\n",
        "    Z = tf.convert_to_tensor(Z)                   # (Tin,batch_size,#dim+1)\n",
        "    Z = tf.transpose(Z,perm=[1,0,2])              # (batch_size,Tin,#dim+1)\n",
        "\n",
        "    # Phase n°2 d'encodage\n",
        "    # Création des représentations cachées des\n",
        "    # concaténations précédentes\n",
        "    hid = []\n",
        "    hid_state = None\n",
        "    cell_state = None\n",
        "    for i in range(input.shape[1]):\n",
        "      hid_state, cell_state = self.encodeur_phase2(Z,hid_state,cell_state,i)\n",
        "      hid.append(hid_state)\n",
        "    hid = tf.convert_to_tensor(hid)               # (Tin,batch_size,#LSTM_encP2)\n",
        "    hid = tf.transpose(hid,perm=[1,0,2])          # (batch_size,Tin,#LSTM_encP2)\n",
        "\n",
        "\n",
        "    # Phase de décodage\n",
        "    # Récupère les états cachés à (T-1)\n",
        "    hid_ = None\n",
        "    cell_ = None\n",
        "    for i in range(0,output_seq.shape[1]-1):\n",
        "      hid_, cell_, vc = self.decodeur(hid,output_seq[:,i:i+1,:],hid_,cell_)\n",
        "    \n",
        "    # hid_  : hT-1    : hidden state à t=T-1\n",
        "    # cell_ : sT-1    : cell state à t=T-1\n",
        "    # vc    : CT-1    : vecteur contexte à t=T-1\n",
        "    \n",
        "    # Estimation des sorties\n",
        "    # hid_ : (batch_size,#LSTM_dec)\n",
        "    # vc   : (batch_size,1,#LSTM_encP2)\n",
        "    Y = []\n",
        "    y = tf.expand_dims(output_seq[:,-1,:],-1)        # y = YT : (batch_size,1,1)\n",
        "    \n",
        "    for i in range(0,self.longueur_sortie):\n",
        "      hid_, cell_, vc = self.decodeur(hid,y,hid_,cell_)\n",
        "      add = tf.keras.layers.concatenate([tf.expand_dims(hid_,1),vc],axis=2)         # (batch_size,1,#LSTM_dec+#LSTM_encP2)\n",
        "      add = tf.transpose(add,perm=[0,2,1])                                          # (batch_size,#LSTM_dec+#LSTM_encP2,1)\n",
        "      sortie = tf.matmul(self.Wy[i,:,:],add)                                      # (#LSTM_dec,#LSTM_dec+#LSTM_encP2) x (batch_size,#LSTM_dec+#LSTM_encP2,1) = (batch_size,#LSTM_dec,1)\n",
        "      sortie = sortie + self.by[i,:,:]                                            # (batch_size,#LSTM_dec,1)\n",
        "      sortie = tf.matmul(tf.transpose(self.vy[i,:,:]),sortie)                     # (1,#LSTM_dec)x(batch_size,#LSTM_dec,1) = (batch_size,1,1)\n",
        "      y = sortie\n",
        "      Y.append(y)\n",
        "\n",
        "    Y = tf.convert_to_tensor(Y)           # Y = (longueur_sortie,batch_size,1,1)\n",
        "    Y = tf.transpose(Y,perm=[1,0,2,3])    # Y = (batch_size,longueur_sortie,1,1)\n",
        "    Y = tf.squeeze(Y,-1)                  # Y = (batch_size,longueur_sortie,1)\n",
        "    return Y"
      ],
      "id": "621ce569",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b19535de",
        "papermill": {
          "duration": 0.087663,
          "end_time": "2021-07-30T20:14:13.253958",
          "exception": false,
          "start_time": "2021-07-30T20:14:13.166295",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Mise en place du modèle DSTP-RNN #1"
      ],
      "id": "b19535de"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:13.440366Z",
          "iopub.status.busy": "2021-07-30T20:14:13.439684Z",
          "iopub.status.idle": "2021-07-30T20:14:13.442111Z",
          "shell.execute_reply": "2021-07-30T20:14:13.442705Z",
          "shell.execute_reply.started": "2021-07-30T11:46:03.984915Z"
        },
        "id": "36e2c904",
        "papermill": {
          "duration": 0.099357,
          "end_time": "2021-07-30T20:14:13.442871",
          "exception": false,
          "start_time": "2021-07-30T20:14:13.343514",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def DSTP_model(config):\n",
        "  entrees_sequences = tf.keras.layers.Input(shape=(config['longueur_sequence'],x_train[0].shape[2]))\n",
        "  sorties_sequence = tf.keras.layers.Input(shape=(config['longueur_sequence'],1))\n",
        "\n",
        "  encodeur_P1 = Encodeur_Phase1(dim_LSTM_enc_P1=config['dim_LSTM_encP1'],drop=config['drop'],regul=config['l2reg'])\n",
        "  encodeur_P2 = Encodeur_Phase2(dim_LSTM_encP2=config['dim_LSTM_encP2'],drop=config['drop'],regul=config['l2reg'])\n",
        "  decodeur = Decodeur(dim_LSTM_encP2=config['dim_LSTM_encP2'],dim_LSTM_dec=config['dim_LSTM_dec'],drop=config['drop'],regul=config['l2reg'])\n",
        "\n",
        "  sortie = Net_DSTPRNN(encodeur_P1,encodeur_P2,decodeur,longueur_sequence=config['longueur_sequence'],longueur_sortie=1, dim_LSTM_dec=config['dim_LSTM_dec'],dim_LSTM_encP2=config['dim_LSTM_encP2'], regul=config['l2reg'],drop=config['drop'])(entrees_sequences,sorties_sequence)\n",
        "\n",
        "  model = tf.keras.Model([entrees_sequences,sorties_sequence],sortie)\n",
        "  return model"
      ],
      "id": "36e2c904",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e21873f",
        "papermill": {
          "duration": 0.087508,
          "end_time": "2021-07-30T20:14:13.618731",
          "exception": false,
          "start_time": "2021-07-30T20:14:13.531223",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Configuration de l'optimiseur"
      ],
      "id": "6e21873f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cad86f29",
        "papermill": {
          "duration": 0.088939,
          "end_time": "2021-07-30T20:14:13.796659",
          "exception": false,
          "start_time": "2021-07-30T20:14:13.707720",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**1. Espace des hyperparamètres**"
      ],
      "id": "cad86f29"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:13.979568Z",
          "iopub.status.busy": "2021-07-30T20:14:13.978766Z",
          "iopub.status.idle": "2021-07-30T20:14:14.368056Z",
          "shell.execute_reply": "2021-07-30T20:14:14.367335Z",
          "shell.execute_reply.started": "2021-07-30T17:33:37.646342Z"
        },
        "id": "55587dd6",
        "papermill": {
          "duration": 0.481591,
          "end_time": "2021-07-30T20:14:14.368206",
          "exception": false,
          "start_time": "2021-07-30T20:14:13.886615",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "from ray import tune\n",
        "\n",
        "def create_search_space():\n",
        "  config = {\n",
        "      \"longueur_sequence\": tune.choice([5,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,90,100]),\n",
        "      \"dim_LSTM_encP1\": tune.choice([16,32,64,128,256]),\n",
        "      \"dim_LSTM_encP2\": tune.choice([16,32,64,128,256]),\n",
        "      \"dim_LSTM_dec\": tune.choice([16,32,64,128,256]),\n",
        "      \"drop\": tune.choice([0.0,0.01,0.1,0.3,0.6]),\n",
        "      \"l2reg\": tune.choice([0.0,0.0001,0.001,0.01]),\n",
        "      \"batch_size\": tune.choice([128,256,512]),\n",
        "      \"lr\": tune.loguniform(1e-4, 1e-1)\n",
        "      }\n",
        "  \n",
        "  initial_best_config = [{\n",
        "      \"longueur_sequence\": 10,\n",
        "      \"dim_LSTM_encP1\": 128,\n",
        "      \"dim_LSTM_encP2\": 128,\n",
        "      \"dim_LSTM_dec\": 128,\n",
        "      \"drop\": 0.0,\n",
        "      \"l2reg\": 0.0,\n",
        "      \"batch_size\": 128,\n",
        "      \"lr\": 0.001\n",
        "      }]\n",
        "\n",
        "  return config,initial_best_config"
      ],
      "id": "55587dd6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:14.556718Z",
          "iopub.status.busy": "2021-07-30T20:14:14.555841Z",
          "iopub.status.idle": "2021-07-30T20:14:14.563905Z",
          "shell.execute_reply": "2021-07-30T20:14:14.563349Z",
          "shell.execute_reply.started": "2021-07-30T11:48:03.414523Z"
        },
        "id": "d63d7e3d",
        "papermill": {
          "duration": 0.105781,
          "end_time": "2021-07-30T20:14:14.564090",
          "exception": false,
          "start_time": "2021-07-30T20:14:14.458309",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "class TuneReporter(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, reporter=None, freq=\"batch\", logs=None):\n",
        "        self.iteration = 0\n",
        "        logs = logs or {}\n",
        "        if freq not in [\"batch\", \"epoch\"]:\n",
        "            raise ValueError(\"{} not supported as a frequency.\".format(freq))\n",
        "        self.freq = freq\n",
        "        super(TuneReporter, self).__init__()\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        from ray import tune\n",
        "        logs = logs or {}\n",
        "        if not self.freq == \"batch\":\n",
        "            return\n",
        "        self.iteration += 1\n",
        "        for metric in list(logs):\n",
        "            if \"loss\" in metric and \"neg_\" not in metric:\n",
        "                logs[\"neg_\" + metric] = -logs[metric]\n",
        "        if \"acc\" in logs:\n",
        "            tune.report(keras_info=logs, mean_accuracy=logs[\"acc\"])\n",
        "        else:\n",
        "            tune.report(keras_info=logs, mean_accuracy=logs.get(\"accuracy\"))\n",
        "    \n",
        "    def on_epoch_end(self, batch, logs=None):\n",
        "        from ray import tune\n",
        "        logs = logs or {}\n",
        "        if not self.freq == \"epoch\":\n",
        "            return\n",
        "        self.iteration += 1\n",
        "        for metric in list(logs):\n",
        "            if \"loss\" in metric and \"neg_\" not in metric:\n",
        "                logs[\"neg_\" + metric] = -logs[metric]\n",
        "        if \"acc\" in logs:\n",
        "            tune.report(keras_info=logs, val_loss=logs['val_loss'], mean_accuracy=logs[\"acc\"])\n",
        "        else:\n",
        "            tune.report(keras_info=logs, val_loss=logs['val_loss'], mean_accuracy=logs.get(\"accuracy\"))"
      ],
      "id": "d63d7e3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:14.749373Z",
          "iopub.status.busy": "2021-07-30T20:14:14.748624Z",
          "iopub.status.idle": "2021-07-30T20:14:14.752248Z",
          "shell.execute_reply": "2021-07-30T20:14:14.751714Z",
          "shell.execute_reply.started": "2021-07-30T11:48:12.007903Z"
        },
        "id": "08fd3725",
        "papermill": {
          "duration": 0.09821,
          "end_time": "2021-07-30T20:14:14.752395",
          "exception": false,
          "start_time": "2021-07-30T20:14:14.654185",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def create_callbacks():\n",
        "    callbacks = []\n",
        "    tune_reporter = TuneReporter(freq=\"epoch\")\n",
        "    callbacks.append(tune_reporter)\n",
        "    return callbacks"
      ],
      "id": "08fd3725",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:14.935302Z",
          "iopub.status.busy": "2021-07-30T20:14:14.934589Z",
          "iopub.status.idle": "2021-07-30T20:14:14.944353Z",
          "shell.execute_reply": "2021-07-30T20:14:14.944910Z"
        },
        "id": "19035438",
        "papermill": {
          "duration": 0.103002,
          "end_time": "2021-07-30T20:14:14.945112",
          "exception": false,
          "start_time": "2021-07-30T20:14:14.842110",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "def train_model(config,):\n",
        "  dataset = prepare_dataset_XY(serie_entrainement_X_norm[:,0:-1],serie_entrainement_X_norm[:,-1:], config['longueur_sequence'],longueur_sortie,config['batch_size'],shift)\n",
        "  dataset_val = prepare_dataset_XY(serie_test_X_norm[:,0:-1],serie_test_X_norm[:,-1:],config['longueur_sequence'],longueur_sortie,config['batch_size'],shift)\n",
        "  x_train, y_train = Create_train(dataset)\n",
        "  x_val, y_val = Create_train(dataset_val)\n",
        "  \n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(resolver)\n",
        "\n",
        "  with strategy.scope():\n",
        "    model = DSTP_model(config)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=config['lr']),loss='mse')\n",
        "  \n",
        "  callbacks = create_callbacks()\n",
        "  history = model.fit(x=[x_train[0],x_train[1]],y=y_train,epochs=1000,callbacks=callbacks,validation_data=([x_val[0],x_val[1]],y_val),batch_size=config['batch_size'])\n",
        "  return history"
      ],
      "id": "19035438",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:15.128201Z",
          "iopub.status.busy": "2021-07-30T20:14:15.127459Z",
          "iopub.status.idle": "2021-07-30T20:14:15.137605Z",
          "shell.execute_reply": "2021-07-30T20:14:15.137051Z",
          "shell.execute_reply.started": "2021-07-30T17:33:49.087825Z"
        },
        "papermill": {
          "duration": 0.103086,
          "end_time": "2021-07-30T20:14:15.137769",
          "exception": false,
          "start_time": "2021-07-30T20:14:15.034683",
          "status": "completed"
        },
        "tags": [],
        "id": "c0844462"
      },
      "source": [
        "from ray.tune import Callback\n",
        "import ftplib\n",
        "\n",
        "class SendFileToFTP(Callback):\n",
        "  def on_trial_complete(self,iteration,trials,trial,**info):\n",
        "    ftp= ftplib.FTP()\n",
        "    HOST = \"62.210.208.36\"\n",
        "    PORT = 2122\n",
        "    ftp.connect(HOST,PORT)\n",
        "    ftp.login('rdpdo','passamoi290876')\n",
        "    os.system(\"zip -r /content/ray_results/RayTuneDSTPI_SP500.zip /content/ray_results\")\n",
        "    localfile = \"/content/ray_results/RayTuneDSTPI_SP500.zip\"\n",
        "    remotefile = \"RayTuneDSTPI_SP500.zip\"\n",
        "    with open(localfile,\"rb\") as file:\n",
        "      ftp.storbinary('STOR %s' %remotefile,file)"
      ],
      "id": "c0844462",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T20:14:15.322414Z",
          "iopub.status.busy": "2021-07-30T20:14:15.321720Z",
          "iopub.status.idle": "2021-07-30T20:14:15.704943Z",
          "shell.execute_reply": "2021-07-30T20:14:15.704176Z",
          "shell.execute_reply.started": "2021-07-30T11:56:01.695209Z"
        },
        "id": "1707f8c2",
        "papermill": {
          "duration": 0.47828,
          "end_time": "2021-07-30T20:14:15.705238",
          "exception": true,
          "start_time": "2021-07-30T20:14:15.226958",
          "status": "failed"
        },
        "tags": []
      },
      "source": [
        "train_dir = os.path.abspath(\"ray_results/train_dir\")\n",
        "val_dir = os.path.abspath(\"ray_results/val_dir\")\n",
        "checkpoint_dir = os.path.abspath(\"ray_results/chackpoint_dir\")\n",
        "results_dir = os.path.abspath(\"ray_results\")\n",
        "\n",
        "!rm -r \"content/ray_results\""
      ],
      "id": "1707f8c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d3eeefa",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "source": [
        "# Laucnh"
      ],
      "id": "6d3eeefa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T11:54:54.652691Z",
          "iopub.status.busy": "2021-07-30T11:54:54.652292Z",
          "iopub.status.idle": "2021-07-30T11:54:59.195772Z",
          "shell.execute_reply": "2021-07-30T11:54:59.194481Z",
          "shell.execute_reply.started": "2021-07-30T11:54:54.652643Z"
        },
        "id": "db9dee01",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/ray_results"
      ],
      "id": "db9dee01",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T11:55:14.137423Z",
          "iopub.status.busy": "2021-07-30T11:55:14.137021Z",
          "iopub.status.idle": "2021-07-30T11:55:14.896975Z",
          "shell.execute_reply": "2021-07-30T11:55:14.894513Z",
          "shell.execute_reply.started": "2021-07-30T11:55:14.137377Z"
        },
        "id": "5b1827d0",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "source": [
        "train_dir = os.path.abspath(\"ray_results/train_dir\")\n",
        "val_dir = os.path.abspath(\"ray_results/val_dir\")\n",
        "checkpoint_dir = os.path.abspath(\"ray_results/chackpoint_dir\")\n",
        "results_dir = os.path.abspath(\"ray_results\")\n",
        "\n",
        "!rm -r \"/content/ray_results\""
      ],
      "id": "5b1827d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T17:33:56.454498Z",
          "iopub.status.busy": "2021-07-30T17:33:56.454089Z",
          "iopub.status.idle": "2021-07-30T17:33:56.464003Z",
          "shell.execute_reply": "2021-07-30T17:33:56.462871Z",
          "shell.execute_reply.started": "2021-07-30T17:33:56.454461Z"
        },
        "id": "816dd822",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "source": [
        "import ray\n",
        "import os\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.suggest import ConcurrencyLimiter\n",
        "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "\n",
        "ray.init(configure_logging=False,ignore_reinit_error=True)\n",
        "config, initial_best_config = create_search_space()\n",
        "\n",
        "scheduler = AsyncHyperBandScheduler(time_attr='training_iteration',metric=\"val_loss\",mode=\"min\",grace_period=500,max_t=1000)\n",
        "search_alg = HyperOptSearch(metric=\"val_loss\",mode=\"min\",points_to_evaluate=initial_best_config)\n",
        "search_alg = ConcurrencyLimiter(search_alg, max_concurrent=1)"
      ],
      "id": "816dd822",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T15:20:34.453343Z",
          "iopub.status.busy": "2021-07-30T15:20:34.452888Z",
          "iopub.status.idle": "2021-07-30T15:20:35.247224Z",
          "shell.execute_reply": "2021-07-30T15:20:35.245871Z",
          "shell.execute_reply.started": "2021-07-30T15:20:34.453300Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "23938a54"
      },
      "source": [
        "!unzip"
      ],
      "id": "23938a54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-07-30T17:33:59.697540Z",
          "iopub.status.busy": "2021-07-30T17:33:59.697141Z"
        },
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": [],
        "id": "25e7eea3"
      },
      "source": [
        "analysis = tune.run(train_model, \n",
        "                    local_dir=results_dir,\n",
        "                    name=\"RayTuneDSTPI_SP500\",\n",
        "                    verbose=0,\n",
        "                    num_samples=1000,\n",
        "                    scheduler=scheduler,\n",
        "                    search_alg=search_alg,\n",
        "                    raise_on_failed_trial=False,\n",
        "                    resources_per_trial={\"cpu\": 1, \"gpu\": 0},\n",
        "                    config=config,\n",
        "                    checkpoint_freq = 1,\n",
        "                    checkpoint_at_end=True,\n",
        "                    resume=True,\n",
        "                    callbacks=[SendFileToFTP()])\n"
      ],
      "id": "25e7eea3",
      "execution_count": null,
      "outputs": []
    }
  ]
}