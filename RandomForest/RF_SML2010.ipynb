{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RF_SML2010.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/ML2/blob/main/RandomForest/RF_SML2010.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Luvr5mg72jn"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4xPbzGikuqw"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# == Prédiction par RF ==\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArXLu7v7ZiZP"
      },
      "source": [
        "# Chargement et correction des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg8UqC4JTMqD"
      },
      "source": [
        "Ce dataset est utilisé pour effectuer la prédiction de la température d'une pièce en fonction de plusieurs paramètres mesurés. La fréquence originale des données est d'une minute, puis a été modifiée à 15minutes avec un filtrage. L'ensemble correspond environ à une durée de 40 jours.  \n",
        "Nous allons utiliser ici la température de la chambre comme cible et sélectionner 18 séries exogènes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNPjm5bA9_u8"
      },
      "source": [
        "**1. Chargement des données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WwTu0bDquT2"
      },
      "source": [
        "!rm *.csv\n",
        "!curl --location --remote-header-name --remote-name \"https://github.com/AlexandreBourrieau/FICHIERS/raw/main/Series_Temporelles/Multi/Data/SMLselected_VSURF_pred.csv\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z66721h8-CY1"
      },
      "source": [
        "**2. Analyse et correction des données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffclRRHzqxYO"
      },
      "source": [
        "# Création de la série sous Pandas\n",
        "df_etude = pd.read_csv(\"SMLselected_VSURF_pred.csv\")\n",
        "df_etude"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oElnLHPailF"
      },
      "source": [
        "df_etude = df_etude.drop(['Unnamed: 0'],axis=1)\n",
        "df_etude"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J2st85d9AKo"
      },
      "source": [
        "Affiche les types :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INH5D4lncQRY"
      },
      "source": [
        "df_etude.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igyc5qUTcdXo"
      },
      "source": [
        "Modifie les type en float32 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_0svvF8chHQ"
      },
      "source": [
        "df_etude = df_etude.astype(dtype='float32')\n",
        "df_etude.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8CVmrVUCMh5"
      },
      "source": [
        "# Séparation des données de test et d'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKbWLsWRCMh6"
      },
      "source": [
        "# Sépare les données en entrainement et tests\n",
        "pourcentage = 0.8\n",
        "temps_separation = int(len(df_etude.values) * pourcentage)\n",
        "date_separation = df_etude.index[temps_separation]\n",
        "\n",
        "serie_entrainement_X = np.array(df_etude.values[:temps_separation],dtype=np.float32)\n",
        "serie_test_X = np.array(df_etude.values[temps_separation:],dtype=np.float32)\n",
        "\n",
        "print(\"Taille de l'entrainement : %d\" %len(serie_entrainement_X))\n",
        "print(\"Taille de la validation : %d\" %len(serie_test_X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsZWwM0-CMh7"
      },
      "source": [
        "**Normalisation des données :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yniWB2X8CMh8"
      },
      "source": [
        "On normalise les données à l'aide de la fonction [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emf7MqosCMh8"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Constrution des séries\n",
        "serie_entrainement_X_norm = []\n",
        "serie_test_X_norm = []\n",
        "\n",
        "for i in range(0,len(df_etude.columns)):\n",
        "  serie_entrainement_X_norm.append(serie_entrainement_X[:,i])\n",
        "  serie_test_X_norm.append(serie_test_X[:,i])\n",
        "\n",
        "serie_entrainement_X_norm = tf.convert_to_tensor(serie_entrainement_X_norm)\n",
        "serie_entrainement_X_norm = tf.transpose(serie_entrainement_X_norm)\n",
        "serie_test_X_norm = tf.convert_to_tensor(serie_test_X_norm)\n",
        "serie_test_X_norm = tf.transpose(serie_test_X_norm)\n",
        "\n",
        "# Initialisaton du MinMaxScaler\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "min_max_scaler.fit(serie_entrainement_X_norm)\n",
        "\n",
        "# Normalisation des séries\n",
        "serie_entrainement_X_norm = min_max_scaler.transform(serie_entrainement_X_norm)\n",
        "serie_test_X_norm = min_max_scaler.transform(serie_test_X_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoBbMQIICMh9"
      },
      "source": [
        "print(serie_entrainement_X_norm.shape)\n",
        "print(serie_test_X_norm.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6THNLf2CMh-"
      },
      "source": [
        "# Affiche quelques séries\n",
        "fig, ax = plt.subplots(constrained_layout=True, figsize=(15,5))\n",
        "\n",
        "ax.plot(df_etude.index[:temps_separation].values,serie_entrainement_X_norm[:,0:5], label=\"X_Ent\")\n",
        "ax.plot(df_etude.index[temps_separation:].values,serie_test_X_norm[:,0:5], label=\"X_Val\")\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TdYJnLSViNl"
      },
      "source": [
        "# Création du modèle RF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZB2zhlwbAFc"
      },
      "source": [
        "Recopie des X et des Y et décalage des Y :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTbD8ONxatyU"
      },
      "source": [
        "X_ent = serie_entrainement_X_norm[:-1,0:-1]\n",
        "Y_ent = np.roll(serie_entrainement_X_norm[:,-1],shift=-1)\n",
        "Y_ent = Y_ent[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUz-nCrpS0xb"
      },
      "source": [
        "X_val = serie_test_X_norm[:-1,0:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD9YBZtjW5I-"
      },
      "source": [
        "# Informations sur les données\n",
        "n = serie_entrainement_X_norm.shape[0]              # Nombre d'observations\n",
        "p = serie_entrainement_X_norm.shape[1]              # Nombre de variables\n",
        "mtry = np.int32(p/3)\n",
        "n_arbres = 2000\n",
        "\n",
        "clf = RandomForestRegressor(n_estimators=n_arbres, bootstrap=True, oob_score=True, max_features=mtry, n_jobs=-1)\n",
        "clf.fit(X_ent,Y_ent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYdWt5jcdH9q"
      },
      "source": [
        "# Prédictions par Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDF7exxVdElk"
      },
      "source": [
        "pred_ent_forest = clf.predict(X_ent)\n",
        "pred_val_forest = clf.predict(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ0edTVEdpbY"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "decalage = 1\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbes originales\n",
        "fig.add_trace(go.Scatter(x=df_etude.index,y=serie_entrainement_X_norm[:,-1],line=dict(color='blue', width=1)))\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[temps_separation:],y=serie_test_X_norm[:,-1],line=dict(color='red', width=1)))\n",
        "\n",
        "#Affiche les prédictions sur l'entrainement\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[1:temps_separation],y=pred_ent_forest, mode='lines', line=dict(color='green', width=1)))\n",
        "\n",
        "#Affiche les prédictions sur les tests\n",
        "fig.add_trace(go.Scatter(x=df_etude.index[temps_separation+1:],y=pred_val_forest, mode='lines', line=dict(color='green', width=1)))\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9wCeoEnMEYv"
      },
      "source": [
        "**Erreurs en single step**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2_ceD69Mju6"
      },
      "source": [
        "mse_ent = tf.keras.losses.mse(serie_entrainement_X_norm[1:,-1],pred_ent_forest)\n",
        "mse_test = tf.keras.losses.mse(serie_test_X_norm[1:,-1],pred_val_forest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FShIaJINHBX"
      },
      "source": [
        "print(mse_ent)\n",
        "print(mse_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}